{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print 10 rows from espn ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "from urllib import request\n",
    "from urllib.error import URLError,HTTPError\n",
    "\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      " <head>\n",
      "  <!-- ESPNFITT | 0fc008bd6250 | 4017 | 8f0c334271d3d2b1f9f3faeb207dd2739645b098 | Thu, 06 Aug 2020 05:38:52 GMT -->\n",
      "  <title data-react-helmet=\"true\">\n",
      "   2019-20 Men's College Basketball Rankings for Final Rankings | ESPN\n",
      "  </title>\n",
      "  <meta content=\"Visit ESPN to view the 2019-20 Men's College Basketball Rankings for Final Rankings\" data-react-helmet=\"true\" name=\"description\"/>\n",
      "  <meta content=\"NCAAM, Men's College Basketball, Rankings, AP Poll, Coaches \n"
     ]
    }
   ],
   "source": [
    "#define url and import data using request and urlopen\n",
    "espnurl = 'https://www.espn.com/mens-college-basketball/rankings'\n",
    "#error handling\n",
    "try:\n",
    "    resp = request.urlopen(espnurl).read().decode('utf8')\n",
    "except URLError as e:\n",
    "    if hasattr(e, 'reason'):\n",
    "        print('We failed to reach a server.')\n",
    "        print('Reason: ', e.reason)\n",
    "    elif hasattr(e, 'code'):\n",
    "        print('The server couldn\\'t fulfill the request.')\n",
    "        print('Error code: ', e.code)\n",
    "else:\n",
    "    soup = bs(resp,'lxml')  #apply beautifulsoup & prettify the output\n",
    "    print(soup.prettify()[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look for top rows from 41st div node \n",
    "# x = soup.find_all('div')[4].findChildren()\n",
    "# print(x[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.title.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.find_all('p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contents\n",
    "for para in soup.find_all('p'):\n",
    "    print(para.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contents\n",
    "body = soup.body\n",
    "for para in body.find_all('p'):\n",
    "    print(para.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(soup.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for url in soup.find_all('a'):\n",
    "#     print(url.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only navigations/urls\n",
    "nav = soup.nav\n",
    "for url in nav.find_all('a'):\n",
    "    print(url.get('href'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for div in soup.find_all('div'):\n",
    "#     print(div.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table = soup.find('table')\n",
    "# print(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = soup.find('table')\n",
    "table_rows = table.find_all('tr')\n",
    "for tr in table_rows:\n",
    "    td = tr.find_all('td')\n",
    "    row= [i.text for i in td]\n",
    "    print(row)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    RK                 Team    REC   PTS TREND\n",
      "0    1         KUKansas(63)   28-3  1623     -\n",
      "1    2       GONZGonzaga(1)   31-2  1547     -\n",
      "2    3         DAYDayton(1)   29-2  1505     -\n",
      "3    4     FSUFlorida State   26-5  1381     -\n",
      "4    5            BAYBaylor   26-4  1337     -\n",
      "5    6  SDSUSan Diego State   30-2  1279     -\n",
      "6    7        CREICreighton   24-7  1154     -\n",
      "7    8           UKKentucky   25-6  1118     -\n",
      "8    9    MSUMichigan State   22-9  1023     -\n",
      "9   10        VILLVillanova   24-7  1011     1\n",
      "10  11             DUKEDuke   25-6   990     1\n",
      "11  12           MDMaryland   24-7   924     -\n",
      "12  13            OREOregon   24-7   892     -\n",
      "13  14        LOULouisville   24-7   768     1\n",
      "14  15       HALLSeton Hall   21-9   727     1\n",
      "15  16          UVAVirginia   23-7   586     1\n",
      "16  17         WISWisconsin  21-10   539     1\n",
      "17  18               BYUBYU   24-8   537     4\n",
      "18  19        OSUOhio State  21-10   459     -\n",
      "19  20            AUBAuburn   25-6   453     -\n",
      "20  21          ILLIllinois  21-10   263     -\n",
      "21  22           HOUHouston   23-8   179     -\n",
      "22  23            BUTButler   22-9   165     1\n",
      "23  24     WVUWest Virginia  21-10   159     2\n",
      "24  25             IOWAIowa  20-11   109     -\n",
      "      RK                 Team    REC  PTS TREND\n",
      "0    1.0         KUKansas(29)   28-3  795     -\n",
      "1    2.0       GONZGonzaga(3)   31-2  760     -\n",
      "2    3.0            DAYDayton   29-2  741     -\n",
      "3    4.0            BAYBaylor   26-4  677     1\n",
      "4    5.0     FSUFlorida State   26-5  656     1\n",
      "5    6.0  SDSUSan Diego State   30-2  601     -\n",
      "6    7.0           UKKentucky   25-6  569     -\n",
      "7    8.0             DUKEDuke   25-6  507     2\n",
      "8    9.0        VILLVillanova   24-7  501     1\n",
      "9    NaN        CREICreighton   24-7  501     -\n",
      "10  11.0           MDMaryland   24-7  486     -\n",
      "11  12.0    MSUMichigan State   22-9  472     -\n",
      "12  13.0        LOULouisville   24-7  427     1\n",
      "13  14.0            OREOregon   24-7  405     1\n",
      "14  15.0       HALLSeton Hall   21-9  387     -\n",
      "15  16.0               BYUBYU   24-8  306     -\n",
      "16  17.0          UVAVirginia   23-7  224     1\n",
      "17  18.0        OSUOhio State  21-10  218     2\n",
      "18  19.0         WISWisconsin  21-10  216     -\n",
      "19  20.0            AUBAuburn   25-6  213     3\n",
      "20  21.0            BUTButler   22-9  130     -\n",
      "21  22.0          ILLIllinois  21-10  124     -\n",
      "22  23.0           HOUHouston   23-8  110     1\n",
      "23  24.0     WVUWest Virginia  21-10  109     1\n",
      "24  25.0             IOWAIowa  20-11   91     -\n"
     ]
    }
   ],
   "source": [
    "dfs = pd.read_html(espnurl)\n",
    "for df in dfs:\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs = pd.read_html('https://www.usnews.com/best-colleges/rankings/national-universities')\n",
    "# for df in dfs:\n",
    "#     print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #define url and import data using request and urlopen\n",
    "# espnurl = 'https://www.usnews.com/best-colleges/rankings/national-universities'\n",
    "# #error handling\n",
    "# try:\n",
    "#     resp = request.urlopen(espnurl).read().decode('utf8')\n",
    "# except URLError as e:\n",
    "#     if hasattr(e, 'reason'):\n",
    "#         print('We failed to reach a server.')\n",
    "#         print('Reason: ', e.reason)\n",
    "#     elif hasattr(e, 'code'):\n",
    "#         print('The server couldn\\'t fulfill the request.')\n",
    "#         print('Error code: ', e.code)\n",
    "# else:\n",
    "#     soup = bs(resp,'lxml')  #applu beautifulsoup & prettify the output\n",
    "#     print(soup.prettify()[:500])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
